# ğŸŒŸ **MediaEval Medico 2025: Explainable VQA for GI Imaging** ğŸŒŸ

ğŸ“‹ [**GitHub Repository**](https://github.com/SushantGautam/MediaEval-Medico-2025) | ğŸ”— [**MediaEval 2025**](https://multimediaeval.github.io/editions/2025/tasks/medico/)  

The **MediaEval Medico 2025 Challenge** ğŸ”¬ focuses on **Visual Question Answering (VQA)** for **Gastrointestinal (GI) imaging**, emphasizing **explainability** ğŸ¤”ğŸ“– to foster **trustworthy AI** for **clinical adoption** âš•ï¸.

This task is a continuation of the long-running **Medico series** at MediaEval, now leveraging the newly developed **Kvasir-VQA-x1 dataset**, designed to support **multimodal reasoning** and **interpretable clinical decision support** ğŸ“ˆ.

---

## ğŸŒŸ **Task Descriptions**

### ğŸ” **Subtask 1: GI Image Question Answering (VQA)**
ğŸ“ˆ **Goal:** Develop AI models that can accurately answer clinical questions using **GI endoscopic images**.

ğŸ§  The task uses **Kvasir-VQA-x1**, an advanced dataset comprising **159,549 QA pairs** from **6,500 original GI images** with:
- Multi-step reasoning questions
- Naturalized medical language
- Complexity scores for curriculum training

ğŸ”  Question types include:
- Yes/No  
- Single-Choice  
- Multiple-Choice  
- Color-related  
- Location-related  
- Numerical Count  
- Merged reasoning-based questions  

---

### ğŸ–Œï¸ **Subtask 2: Multimodal Explainability for Clinicians**

ğŸ“ˆ **Goal:** Move beyond prediction â€” provide **interpretable, multimodal explanations** that support:
- Region-based visual highlights ğŸ–¼ï¸
- Textual clinical justifications ğŸ“–
- Confidence or uncertainty estimates ğŸ“‰

ğŸ”„ Each explanation should reflect **clinical reasoning** to assist human experts in understanding AI output.

âš ï¸ **Note:** Participation in Subtask 2 requires completion of Subtask 1.

---

## ğŸ“‚ **Dataset Overview: Kvasir-VQA-x1**

ğŸ“ Built on top of **HyperKvasir** and **Kvasir-Instrument**, the **Kvasir-VQA-x1** dataset introduces:
- ğŸ§¬ **159,549 QA pairs**
- ğŸ–¼ï¸ **6,500 original GI images**
- â™»ï¸ **10 weakly augmented images per original** (augmentation script provided)
- ğŸ§  **Question complexity levels (1â€“3)**
- ğŸ§ª **Realistic medical question reformulations and merging using LLMs**

ğŸ› ï¸ Dataset available at: [**SimulaMet on Hugging Face**](https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1)

---

## ğŸ”® **Evaluation Methodology**

### âœ… **Subtask 1: VQA Performance**
- **Metrics:** BLEU, ROUGE (1/2/L), METEOR
- **Settings:**  
  - **Original Setting:** Clean images only  
  - **Transformed Setting:** Augmented images for robustness testing  
- **Criteria:** Accuracy, relevance, and medical correctness

### ğŸ’¬ **Subtask 2: Explainability Score**
- Expert-reviewed metrics:
  - Visual clarity
  - Medical relevance
  - Cross-modal coherence
- Encourages **interpretable and safe model behavior**

---

## ğŸ› ï¸ **Tools & Resources**
- ğŸ“¦ Scripts for augmentation, splits, and baselines
- ğŸ”— Submission templates (coming soon)
- ğŸ¤– LLM-based merging prompts and fine-tuned model configurations
- ğŸ§  Suggested frameworks: attention, saliency maps, probabilistic modeling

---

## ğŸ“Š **Research Questions for Exploration**
- How can we balance **performance and interpretability**?
- What role does **uncertainty** play in clinical explanation?
- Can we design a scoring mechanism for **explanation quality**?
- What helps **clinicians trust** model outputs?

---

## ğŸ‘¥ **Target Group**
ğŸ“ Students, researchers, and professionals from:
- Medical Imaging  
- Multimedia AI  
- Computer Vision & NLP  
- Explainable AI  

ğŸ’¬ Student mentoring available!

---

## ğŸ—“ï¸ **Timeline (Preliminary)**

- ğŸ“¦ **14 May 2025**: Development data release _(passed)_
- ğŸ§ª **30 June 2025**: Validation data available  
- ğŸ“„ **12 September 2025**: Submission deadline  
- ğŸ† **26 September 2025**: Results announced  
- ğŸ“ **8 October 2025**: Working Notes deadline  
- ğŸ« **25â€“26 October 2025**: MediaEval Workshop (Dublin + Online)

---

## ğŸ’¼ **Organizers**  
âœ¨ For any queries, contact our team:  
- ğŸ‘¨â€ğŸ”¬ Steven A. Hicks: [steven@simula.no](mailto:steven@simula.no)  
- ğŸ§‘â€ğŸ’» Michael A. Riegler: [michael@simula.no](mailto:michael@simula.no)  
- ğŸ§‘â€ğŸ”¬ Vajira Thambawita: [vajira@simula.no](mailto:vajira@simula.no)  
- ğŸ‘¨â€ğŸ« PÃ¥l Halvorsen: [paalh@simula.no](mailto:paalh@simula.no)  
- ğŸ§‘â€ğŸ“ [Sushant Gautam](https://sushant.info.np): [sushant@simula.no](mailto:sushant@simula.no)  

---

## ğŸ”— **Join Us**  
Letâ€™s build the future of **trustworthy, explainable medical AI**.  
ğŸŒŸ GI diagnostics needs interpretable answers. Your model can help save lives.

ğŸ“ Register at [**MediaEval 2025**](https://multimediaeval.github.io/editions/2025/)  
ğŸ“ Challenge repo: [**GitHub**](https://github.com/SushantGautam/MediaEval-Medico-2025)

ğŸš€ *Develop explainable AI. Help doctors. Improve lives.*
